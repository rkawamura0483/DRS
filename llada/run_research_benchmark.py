#!/usr/bin/env python3
"""
Self-Correcting Adaptive Inference Scheduling Research Benchmark

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ç ”ç©¶ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ï¼š
GSM8K, MATH, HumanEval, MBPPã§25ã‚µãƒ³ãƒ—ãƒ«ãšã¤ï¼ˆåˆè¨ˆ100ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã‚’ä½¿ç”¨ã—ã¦
ã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®æ™‚é–“ã¨ã‚¢ã‚­ãƒ¥ãƒ©ã‚·ãƒ¼ã‚’æ¸¬å®šã—ã¾ã™ã€‚
"""

from benchmark_runner import BenchmarkRunner
import os
import sys
import time
import json
import argparse
from pathlib import Path
from typing import Dict, List, Any
import torch
import numpy as np
from tqdm import tqdm

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent))


class ResearchBenchmark:
    """
    ã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ç ”ç©¶ç”¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹

    ç ”ç©¶ç›®æ¨™:
    - ã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚° vs é™çš„æ‰‹æ³•ã®æ¯”è¼ƒ
    - æ™‚é–“ã¨ã‚¢ã‚­ãƒ¥ãƒ©ã‚·ãƒ¼ã®ä¸¡æ–¹ã‚’æ¸¬å®š
    - GSM8K, MATH, HumanEval, MBPP ã®4ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è©•ä¾¡
    - å„25ã‚µãƒ³ãƒ—ãƒ«ï¼ˆåˆè¨ˆ100ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    """

    def __init__(self, model_name: str = "GSAI-ML/LLaDA-8B-Instruct", device: str = "auto"):
        """ç ”ç©¶ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®åˆæœŸåŒ–"""
        print("ğŸš€ Self-Correcting Adaptive Inference Scheduling Research Benchmark")
        print("="*70)

        self.runner = BenchmarkRunner(model_name=model_name, device=device)

        # ç ”ç©¶ç”¨è¨­å®š
        self.research_config = {
            'samples_per_dataset': 25,  # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ25ã‚µãƒ³ãƒ—ãƒ«
            'total_expected_samples': 100,  # åˆè¨ˆ100ã‚µãƒ³ãƒ—ãƒ«
            'gen_length': 256,  # ç”Ÿæˆé•·
            'target_datasets': ['gsm8k', 'math', 'humaneval', 'mbpp']
        }

        # ã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°è¨­å®šï¼ˆè«–æ–‡ã®è¨­å®šã«åŸºã¥ãï¼‰
        self.adaptive_config = {
            'to_quality_threshold': 0.80,      # å“è³ªãƒ¢ãƒ¼ãƒ‰ã¸ã®åˆ‡ã‚Šæ›¿ãˆé–¾å€¤
            'to_efficiency_threshold': 0.90,   # åŠ¹ç‡ãƒ¢ãƒ¼ãƒ‰ã¸ã®åˆ‡ã‚Šæ›¿ãˆé–¾å€¤
            'confidence_window_size': 2,       # ä¿¡é ¼åº¦ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
            'high_efficiency_params': {        # é«˜åŠ¹ç‡ãƒ¢ãƒ¼ãƒ‰è¨­å®š
                'block_size': 32,
                'threshold': 0.70
            },
            'high_quality_params': {           # é«˜å“è³ªãƒ¢ãƒ¼ãƒ‰è¨­å®š
                'block_size': 8,
                'threshold': 0.90
            }
        }

        print(f"ğŸ“Š ç ”ç©¶è¨­å®š:")
        print(f"   å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {self.research_config['samples_per_dataset']}ã‚µãƒ³ãƒ—ãƒ«")
        print(f"   åˆè¨ˆäºˆå®šã‚µãƒ³ãƒ—ãƒ«: {self.research_config['total_expected_samples']}")
        print(
            f"   å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {', '.join(self.research_config['target_datasets'])}")
        print(f"   ã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–è¨­å®š: {self.adaptive_config}")
        print()

    def run_research_evaluation(self) -> Dict[str, Any]:
        """
        ç ”ç©¶è©•ä¾¡ã‚’å®Ÿè¡Œ

        Returns:
            ç ”ç©¶çµæœè¾æ›¸
        """
        print("ğŸ”¬ ç ”ç©¶è©•ä¾¡é–‹å§‹...")

        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        start_time = time.time()

        results = self.runner.run_comprehensive_benchmark(
            samples_per_dataset=self.research_config['samples_per_dataset'],
            gen_length=self.research_config['gen_length'],
            scheduler_config=self.adaptive_config
        )

        total_time = time.time() - start_time

        # ç ”ç©¶ç‰¹åŒ–ã®åˆ†æã‚’è¿½åŠ 
        research_analysis = self._analyze_research_results(results)

        # çµæœã«ç ”ç©¶æƒ…å ±ã‚’è¿½åŠ 
        results['research_analysis'] = research_analysis
        results['total_benchmark_time'] = total_time
        results['research_config'] = self.research_config

        return results

    def _analyze_research_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç ”ç©¶çµæœã®ç‰¹åŒ–åˆ†æ

        Args:
            results: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ

        Returns:
            ç ”ç©¶åˆ†æçµæœ
        """
        print("\nğŸ” ç ”ç©¶çµæœåˆ†æä¸­...")

        analysis = {
            'hypothesis_validation': {},
            'performance_gains': {},
            'mode_switching_analysis': {},
            'dataset_specific_insights': {}
        }

        summary = results.get('summary', {})

        if 'adaptive' in summary and 'static' in summary:
            adaptive = summary['adaptive']
            static = summary['static']

            # ä»®èª¬æ¤œè¨¼
            analysis['hypothesis_validation'] = {
                'time_improvement_achieved': adaptive['avg_time_per_sample'] < static['avg_time_per_sample'],
                'accuracy_maintained_or_improved': adaptive['accuracy'] >= static['accuracy'],
                'nfe_reduction_achieved': adaptive['avg_nfe_per_sample'] < static['avg_nfe_per_sample'],
                'adaptation_occurred': adaptive.get('total_adaptations', 0) > 0
            }

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„
            time_improvement = (
                static['avg_time_per_sample'] - adaptive['avg_time_per_sample']) / static['avg_time_per_sample'] * 100
            accuracy_change = (adaptive['accuracy'] - static['accuracy']) * 100
            nfe_improvement = (
                static['avg_nfe_per_sample'] - adaptive['avg_nfe_per_sample']) / static['avg_nfe_per_sample'] * 100

            analysis['performance_gains'] = {
                'time_improvement_percent': time_improvement,
                'accuracy_change_percent': accuracy_change,
                'nfe_improvement_percent': nfe_improvement,
                'total_adaptations': adaptive.get('total_adaptations', 0),
                'avg_block_size': adaptive.get('avg_block_size', 0)
            }

            # ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆåˆ†æ
            analysis['mode_switching_analysis'] = {
                'adaptations_per_sample': adaptive.get('total_adaptations', 0) / adaptive.get('total_samples', 1),
                # 32ã¯é™çš„ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º
                'avg_block_size_vs_static': adaptive.get('avg_block_size', 0) / 32.0
            }

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥æ´å¯Ÿ
        breakdown = results.get('dataset_breakdown', {})
        for dataset_name, dataset_results in breakdown.items():
            if 'adaptive' in dataset_results and 'static' in dataset_results:
                adaptive_ds = dataset_results['adaptive']
                static_ds = dataset_results['static']

                time_improvement_ds = (
                    static_ds['avg_time'] - adaptive_ds['avg_time']) / static_ds['avg_time'] * 100
                accuracy_change_ds = (
                    adaptive_ds['accuracy'] - static_ds['accuracy']) * 100

                analysis['dataset_specific_insights'][dataset_name] = {
                    'time_improvement_percent': time_improvement_ds,
                    'accuracy_change_percent': accuracy_change_ds,
                    'adaptive_better_time': adaptive_ds['avg_time'] < static_ds['avg_time'],
                    'adaptive_better_accuracy': adaptive_ds['accuracy'] >= static_ds['accuracy']
                }

        return analysis

    def print_research_summary(self, results: Dict[str, Any]):
        """
        ç ”ç©¶çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º

        Args:
            results: ç ”ç©¶çµæœ
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“Š ç ”ç©¶çµæœã‚µãƒãƒªãƒ¼: Self-Correcting Adaptive Inference Scheduling")
        print(f"{'='*70}")

        # åŸºæœ¬çµæœè¡¨ç¤º
        self.runner.print_results_summary(results)

        # ç ”ç©¶ç‰¹åŒ–åˆ†æ
        analysis = results.get('research_analysis', {})

        print(f"\nğŸ”¬ ç ”ç©¶ä»®èª¬æ¤œè¨¼:")
        hypothesis = analysis.get('hypothesis_validation', {})
        print(
            f"   âœ“ æ™‚é–“æ”¹å–„é”æˆ: {'âœ…' if hypothesis.get('time_improvement_achieved', False) else 'âŒ'}")
        print(
            f"   âœ“ ã‚¢ã‚­ãƒ¥ãƒ©ã‚·ãƒ¼ç¶­æŒ/æ”¹å–„: {'âœ…' if hypothesis.get('accuracy_maintained_or_improved', False) else 'âŒ'}")
        print(
            f"   âœ“ NFEå‰Šæ¸›é”æˆ: {'âœ…' if hypothesis.get('nfe_reduction_achieved', False) else 'âŒ'}")
        print(
            f"   âœ“ ã‚¢ãƒ€ãƒ—ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç™ºç”Ÿ: {'âœ…' if hypothesis.get('adaptation_occurred', False) else 'âŒ'}")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„
        gains = analysis.get('performance_gains', {})
        print(f"\nğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„:")
        print(f"   æ™‚é–“æ”¹å–„: {gains.get('time_improvement_percent', 0):+.1f}%")
        print(f"   ã‚¢ã‚­ãƒ¥ãƒ©ã‚·ãƒ¼å¤‰åŒ–: {gains.get('accuracy_change_percent', 0):+.1f}%")
        print(f"   NFEæ”¹å–„: {gains.get('nfe_improvement_percent', 0):+.1f}%")
        print(f"   åˆè¨ˆã‚¢ãƒ€ãƒ—ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: {gains.get('total_adaptations', 0)}")

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥æ´å¯Ÿ
        insights = analysis.get('dataset_specific_insights', {})
        print(f"\nğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
        for dataset, insight in insights.items():
            print(f"   {dataset.upper()}:")
            print(
                f"     æ™‚é–“æ”¹å–„: {insight.get('time_improvement_percent', 0):+.1f}%")
            print(
                f"     ã‚¢ã‚­ãƒ¥ãƒ©ã‚·ãƒ¼å¤‰åŒ–: {insight.get('accuracy_change_percent', 0):+.1f}%")

        # å…¨ä½“è©•ä¾¡
        print(f"\nğŸ† å…¨ä½“è©•ä¾¡:")
        overall_success = (
            hypothesis.get('time_improvement_achieved', False) and
            hypothesis.get('accuracy_maintained_or_improved', False) and
            hypothesis.get('adaptation_occurred', False)
        )
        print(f"   ç ”ç©¶ä»®èª¬ã®æˆåŠŸ: {'âœ… æˆåŠŸ' if overall_success else 'âŒ éƒ¨åˆ†çš„æˆåŠŸ'}")

        total_time = results.get('total_benchmark_time', 0)
        total_samples = results.get('config', {}).get('total_samples', 0)
        print(f"   ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œæ™‚é–“: {total_time:.1f}ç§’")
        print(f"   è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°: {total_samples}")

    def save_research_results(self, results: Dict[str, Any], output_dir: str = "research_results"):
        """
        ç ”ç©¶çµæœã‚’ä¿å­˜

        Args:
            results: ç ”ç©¶çµæœ
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        timestamp = time.strftime("%Y%m%d_%H%M%S")

        # è©³ç´°çµæœä¿å­˜
        detailed_file = output_path / \
            f"adaptive_scheduling_research_{timestamp}.json"
        with open(detailed_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)

        # ç ”ç©¶ã‚µãƒãƒªãƒ¼ä¿å­˜
        summary_file = output_path / f"research_summary_{timestamp}.md"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(
                "# Self-Correcting Adaptive Inference Scheduling Research Results\n\n")

            analysis = results.get('research_analysis', {})
            hypothesis = analysis.get('hypothesis_validation', {})
            gains = analysis.get('performance_gains', {})

            f.write("## Hypothesis Validation\n\n")
            f.write(
                f"- Time Improvement: {'âœ…' if hypothesis.get('time_improvement_achieved', False) else 'âŒ'}\n")
            f.write(
                f"- Accuracy Maintained/Improved: {'âœ…' if hypothesis.get('accuracy_maintained_or_improved', False) else 'âŒ'}\n")
            f.write(
                f"- NFE Reduction: {'âœ…' if hypothesis.get('nfe_reduction_achieved', False) else 'âŒ'}\n")
            f.write(
                f"- Adaptations Occurred: {'âœ…' if hypothesis.get('adaptation_occurred', False) else 'âŒ'}\n\n")

            f.write("## Performance Gains\n\n")
            f.write(
                f"- Time Improvement: {gains.get('time_improvement_percent', 0):+.1f}%\n")
            f.write(
                f"- Accuracy Change: {gains.get('accuracy_change_percent', 0):+.1f}%\n")
            f.write(
                f"- NFE Improvement: {gains.get('nfe_improvement_percent', 0):+.1f}%\n")
            f.write(
                f"- Total Adaptations: {gains.get('total_adaptations', 0)}\n\n")

            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥çµæœ
            f.write("## Dataset-Specific Results\n\n")
            breakdown = results.get('dataset_breakdown', {})
            for dataset, ds_results in breakdown.items():
                if 'adaptive' in ds_results and 'static' in ds_results:
                    adaptive = ds_results['adaptive']
                    static = ds_results['static']

                    f.write(f"### {dataset.upper()}\n")
                    f.write(
                        f"- Adaptive: Accuracy={adaptive['accuracy']*100:.1f}%, Time={adaptive['avg_time']:.2f}s\n")
                    f.write(
                        f"- Static: Accuracy={static['accuracy']*100:.1f}%, Time={static['avg_time']:.2f}s\n\n")

        print(f"\nğŸ’¾ ç ”ç©¶çµæœä¿å­˜å®Œäº†:")
        print(f"   è©³ç´°çµæœ: {detailed_file}")
        print(f"   ç ”ç©¶ã‚µãƒãƒªãƒ¼: {summary_file}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Self-Correcting Adaptive Inference Scheduling Research Benchmark",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # åŸºæœ¬çš„ãªç ”ç©¶ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
  python run_research_benchmark.py
  
  # å°è¦æ¨¡ãƒ†ã‚¹ãƒˆï¼ˆå„5ã‚µãƒ³ãƒ—ãƒ«ï¼‰
  python run_research_benchmark.py --quick-test
  
  # ã‚«ã‚¹ã‚¿ãƒ è¨­å®š
  python run_research_benchmark.py --samples 10 --gen-length 128
        """
    )

    # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument("--model", default="GSAI-ML/LLaDA-8B-Instruct",
                        help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å")
    parser.add_argument("--device", default="auto",
                        help="ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ (auto/cuda/cpu)")
    parser.add_argument("--samples", type=int, default=25,
                        help="å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒ«æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 25)")
    parser.add_argument("--gen-length", type=int, default=256,
                        help="ç”Ÿæˆé•· (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 256)")

    # ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument("--quick-test", action="store_true",
                        help="ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ (å„5ã‚µãƒ³ãƒ—ãƒ«)")

    # å‡ºåŠ›è¨­å®š
    parser.add_argument("--output-dir", default="research_results",
                        help="çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šã®å¾®èª¿æ•´ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    scheduler_group = parser.add_argument_group('advanced', 'ã‚¢ãƒ‰ãƒãƒ³ã‚¹ãƒ‰è¨­å®š')
    scheduler_group.add_argument("--to-quality-threshold", type=float, default=0.80,
                                 help="å“è³ªãƒ¢ãƒ¼ãƒ‰ã¸ã®åˆ‡ã‚Šæ›¿ãˆé–¾å€¤")
    scheduler_group.add_argument("--to-efficiency-threshold", type=float, default=0.90,
                                 help="åŠ¹ç‡ãƒ¢ãƒ¼ãƒ‰ã¸ã®åˆ‡ã‚Šæ›¿ãˆé–¾å€¤")

    args = parser.parse_args()

    # ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®å ´åˆã¯è¨­å®šã‚’èª¿æ•´
    if args.quick_test:
        args.samples = 5
        args.gen_length = 128
        print("ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ5ã‚µãƒ³ãƒ—ãƒ«")

    # ç ”ç©¶ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯åˆæœŸåŒ–
    research_benchmark = ResearchBenchmark(
        model_name=args.model,
        device=args.device
    )

    # ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’èª¿æ•´
    research_benchmark.research_config['samples_per_dataset'] = args.samples
    research_benchmark.research_config['gen_length'] = args.gen_length

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šã®å¾®èª¿æ•´
    research_benchmark.adaptive_config['to_quality_threshold'] = args.to_quality_threshold
    research_benchmark.adaptive_config['to_efficiency_threshold'] = args.to_efficiency_threshold

    try:
        print(f"\nğŸ¯ ç ”ç©¶ç›®æ¨™: Self-Correcting Adaptive Inference Schedulingã®æœ‰åŠ¹æ€§æ¤œè¨¼")
        print(f"ğŸ“Š è©•ä¾¡è¦æ¨¡: {args.samples * 4}ã‚µãƒ³ãƒ—ãƒ« ({args.samples}Ã—4ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)")

        # ç ”ç©¶è©•ä¾¡å®Ÿè¡Œ
        results = research_benchmark.run_research_evaluation()

        # çµæœè¡¨ç¤º
        research_benchmark.print_research_summary(results)

        # çµæœä¿å­˜
        research_benchmark.save_research_results(results, args.output_dir)

        print(f"\nğŸ‰ ç ”ç©¶ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†!")

        # æˆåŠŸåˆ¤å®š
        analysis = results.get('research_analysis', {})
        hypothesis = analysis.get('hypothesis_validation', {})

        if (hypothesis.get('time_improvement_achieved', False) and
                hypothesis.get('accuracy_maintained_or_improved', False)):
            print(f"âœ… ç ”ç©¶ä»®èª¬ãŒæ¤œè¨¼ã•ã‚Œã¾ã—ãŸï¼")
        else:
            print(f"âš ï¸  ç ”ç©¶ä»®èª¬ã®éƒ¨åˆ†çš„æ¤œè¨¼ - ã•ã‚‰ãªã‚‹åˆ†æãŒå¿…è¦ã§ã™")

    except Exception as e:
        print(f"âŒ ç ”ç©¶ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
