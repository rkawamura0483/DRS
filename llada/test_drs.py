# æ”¹å–„ç‰ˆDRSæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
import logging
import re
from collections import Counter

import numpy as np
import torch
import torch.nn.functional as F
from generate import generate, generate_with_conservative_drs
from model.modeling_llada import LLaDAModelLM
from transformers import AutoTokenizer

# æ—¥æœ¬èªã®ã‚³ãƒ¡ãƒ³ãƒˆã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ä¿æŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ImprovedQualityEvaluator:
    """å¤§å¹…æ”¹å–„ã•ã‚ŒãŸå“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, tokenizer):
        self.tokenizer = tokenizer

    def check_semantic_consistency(self, prompt, baseline_text, drs_text):
        """æ„å‘³çš„ä¸€è²«æ€§ã®è©•ä¾¡ - æœ€é‡è¦æŒ‡æ¨™"""
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        prompt_lower = prompt.lower()
        baseline_lower = baseline_text.lower()
        drs_lower = drs_text.lower()

        # é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä¸€è‡´åº¦ãƒã‚§ãƒƒã‚¯
        if "rectangular" in prompt_lower and "garden" in prompt_lower:
            # é•·æ–¹å½¢ã®åº­ã®å•é¡Œ
            baseline_has_rectangle = any(word in baseline_lower for word in [
                                         "rectangular", "rectangle", "length", "width"])
            drs_has_rectangle = any(word in drs_lower for word in [
                                    "rectangular", "rectangle", "length", "width"])

            # å††ã®æ¦‚å¿µãŒæ··å…¥ã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
            baseline_has_circle = any(word in baseline_lower for word in [
                                      "circle", "radius", "Ï€", "pi"])
            drs_has_circle = any(word in drs_lower for word in [
                                 "circle", "radius", "Ï€", "pi"])

            if baseline_has_rectangle and not baseline_has_circle:
                if drs_has_rectangle and not drs_has_circle:
                    return 1.0  # å®Œå…¨ä¸€è‡´
                elif drs_has_circle:
                    return 0.0  # é‡å¤§ãªæ„å‘³çš„ã‚¨ãƒ©ãƒ¼
                else:
                    return 0.5  # éƒ¨åˆ†çš„

        elif "python" in prompt_lower and "function" in prompt_lower:
            # ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å•é¡Œ
            baseline_has_code = "def " in baseline_lower and "return" in baseline_lower
            drs_has_code = "def " in drs_lower and "return" in drs_lower

            if baseline_has_code:
                if drs_has_code:
                    return 1.0
                else:
                    return 0.0  # ã‚³ãƒ¼ãƒ‰ãŒç”Ÿæˆã•ã‚Œã¦ã„ãªã„

        # ä¸€èˆ¬çš„ãªä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        baseline_words = set(baseline_lower.split())
        drs_words = set(drs_lower.split())
        overlap = len(baseline_words & drs_words) / max(len(baseline_words), 1)

        return min(1.0, overlap)

    def evaluate_repetition_penalty(self, text):
        """åå¾©ãƒšãƒŠãƒ«ãƒ†ã‚£ã®è©•ä¾¡"""
        if not text:
            return 1.0

        sentences = re.split(r'[.!?]+', text)
        valid_sentences = [s.strip() for s in sentences if len(s.strip()) > 5]

        if len(valid_sentences) <= 1:
            return 1.0

        # å®Œå…¨ã«åŒä¸€ã®æ–‡ã®æ¤œå‡º
        sentence_counts = Counter(valid_sentences)
        max_repetition = max(sentence_counts.values())

        if max_repetition >= 3:
            return 0.1  # é‡å¤§ãªåå¾©
        elif max_repetition == 2:
            return 0.5  # è»½åº¦ã®åå¾©

        # é€£ç¶šã™ã‚‹åŒä¸€èªå¥ã®æ¤œå‡º
        words = text.split()
        consecutive_count = 0
        for i in range(len(words) - 2):
            if words[i] == words[i+1] == words[i+2]:
                consecutive_count += 1

        if consecutive_count > 5:
            return 0.1
        elif consecutive_count > 2:
            return 0.5

        return 1.0

    def evaluate_completeness(self, text, expected_elements):
        """å®Œå…¨æ€§ã®è©•ä¾¡"""
        if not text:
            return 0.0

        text_lower = text.lower()
        found_elements = sum(
            1 for element in expected_elements if element.lower() in text_lower)

        return found_elements / max(len(expected_elements), 1)

    def comprehensive_quality_score(self, prompt, baseline_text, drs_text):
        """åŒ…æ‹¬çš„å“è³ªã‚¹ã‚³ã‚¢ - æ„å‘³çš„ä¸€è²«æ€§ã‚’æœ€é‡è¦è¦–"""
        # 1. æ„å‘³çš„ä¸€è²«æ€§ (æœ€é‡è¦ - 60%ã®é‡ã¿)
        semantic_consistency = self.check_semantic_consistency(
            prompt, baseline_text, drs_text)

        # 2. åå¾©ãƒšãƒŠãƒ«ãƒ†ã‚£ (30%ã®é‡ã¿)
        repetition_score = self.evaluate_repetition_penalty(drs_text)

        # 3. åŸºæœ¬çš„ãªå®Œå…¨æ€§ (10%ã®é‡ã¿)
        drs_length = len(drs_text.split())
        baseline_length = len(baseline_text.split())
        length_ratio = min(
            1.0, drs_length / max(baseline_length, 1)) if baseline_length > 0 else 0

        # é‡ã¿ä»˜ãæœ€çµ‚ã‚¹ã‚³ã‚¢
        final_score = (
            0.6 * semantic_consistency +
            0.3 * repetition_score +
            0.1 * length_ratio
        )

        return final_score, {
            'semantic_consistency': semantic_consistency,
            'repetition_score': repetition_score,
            'length_ratio': length_ratio
        }


def enhanced_ambiguity_calculation_with_context(confidence_scores, threshold, prompt_context=None):
    """æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸæ”¹å–„ã•ã‚ŒãŸæ›–æ˜§åº¦è¨ˆç®—"""
    valid_scores = confidence_scores[confidence_scores != -np.inf]
    if len(valid_scores) == 0:
        return 0.0

    # åŸºæœ¬çš„ãªé–¾å€¤ãƒ™ãƒ¼ã‚¹æ›–æ˜§åº¦
    threshold_ambiguity = (valid_scores < threshold).float().mean().item()

    # åˆ†æ•£ãƒ™ãƒ¼ã‚¹ã®æ›–æ˜§åº¦ï¼ˆä¸å®‰å®šæ€§æŒ‡æ¨™ï¼‰
    variance_ambiguity = min(1.0, valid_scores.var().item() * 10)  # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´

    # çµ±åˆæ›–æ˜§åº¦ã‚¹ã‚³ã‚¢ï¼ˆã‚ˆã‚Šä¿å®ˆçš„ã«ï¼‰
    combined_ambiguity = 0.7 * threshold_ambiguity + 0.3 * variance_ambiguity

    return combined_ambiguity


def test_enhanced_drs_validation():
    """å¤§å¹…æ”¹å–„ç‰ˆDRSæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”¬ å¤§å¹…æ”¹å–„ç‰ˆDRSæ¤œè¨¼é–‹å§‹ (ãƒ‡ãƒã‚¤ã‚¹: {device})")

    # ã‚ˆã‚Šå³é¸ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    test_prompts = [
        "Calculate the area of a rectangular garden with length 15 meters and width 8 meters.",
        "Write a Python function to find the factorial of a number using recursion.",
    ]

    try:
        print("ğŸ“¦ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­...")
        model = LLaDAModelLM.from_pretrained(
            'GSAI-ML/LLaDA-8B-Instruct',
            trust_remote_code=True,
            torch_dtype=torch.bfloat16
        ).to(device).eval()

        tokenizer = AutoTokenizer.from_pretrained(
            'GSAI-ML/LLaDA-8B-Instruct',
            trust_remote_code=True
        )
        model.tokenizer = tokenizer

        # ãƒã‚¹ã‚¯IDå–å¾—
        mask_id = tokenizer.mask_token_id or model.config.mask_token_id or 126336
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº† (mask_id={mask_id})")

        # æ”¹å–„ã•ã‚ŒãŸå“è³ªè©•ä¾¡å™¨ã®åˆæœŸåŒ–
        evaluator = ImprovedQualityEvaluator(tokenizer)

        # ã‚ˆã‚Šå®Ÿç”¨çš„ã§å®‰å…¨ãªãƒ†ã‚¹ãƒˆè¨­å®š
        gen_length = 256
        block_length = 32
        total_steps = 128

        results = []

        for i, prompt in enumerate(test_prompts):
            print(f"\n{'='*80}")
            print(f"ğŸ“ ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ {i+1}: {prompt}")
            print(f"{'='*80}")

            m = [{"role": "user", "content": prompt}]
            prompt_formatted = tokenizer.apply_chat_template(
                m, add_generation_prompt=True, tokenize=False)
            input_ids = tokenizer(prompt_formatted)['input_ids']
            input_ids = torch.tensor(input_ids).to(device).unsqueeze(0)

            # å“è³ªé‡è¦–ã®å³æ ¼ãªãƒ†ã‚¹ãƒˆæ¡ä»¶
            test_conditions = [
                {'t_base': 12, 'threshold': 0.95, 'name': 'è¶…ä¿å®ˆçš„è¨­å®š'},  # æœ€é«˜å“è³ªé‡è¦–
                {'t_base': 10, 'threshold': 0.92, 'name': 'é«˜å“è³ªè¨­å®š'},   # é«˜å“è³ª
                {'t_base': 8, 'threshold': 0.90, 'name': 'ãƒãƒ©ãƒ³ã‚¹è¨­å®š'},   # ãƒãƒ©ãƒ³ã‚¹
            ]

            for condition in test_conditions:
                print(f"\n{'-'*60}")
                print(
                    f"ğŸ§ª {condition['name']} (t_base={condition['t_base']}, threshold={condition['threshold']})")
                print(f"{'-'*60}")

                # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç”Ÿæˆ
                print("ğŸ¯ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç”Ÿæˆä¸­...")
                baseline_out, baseline_nfe = generate(
                    model, input_ids, steps=total_steps, gen_length=gen_length,
                    block_length=block_length, temperature=0., remasking='low_confidence',
                    mask_id=mask_id
                )

                # ä¿å®ˆçš„DRSç”Ÿæˆ
                print("âš¡ å¤§å¹…æ”¹å–„ç‰ˆDRSç”Ÿæˆä¸­...")
                drs_out, drs_nfe, ambiguity_scores = generate_with_conservative_drs(
                    model, input_ids, steps=total_steps, gen_length=gen_length,
                    block_length=block_length, temperature=0.,
                    threshold=condition['threshold'], t_base=condition['t_base'],
                    mask_id=mask_id
                )

                # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                baseline_text = tokenizer.batch_decode(
                    baseline_out[:, input_ids.shape[1]:], skip_special_tokens=True)[0]
                drs_text = tokenizer.batch_decode(
                    drs_out[:, input_ids.shape[1]:], skip_special_tokens=True)[0]

                # å¤§å¹…æ”¹å–„ã•ã‚ŒãŸå“è³ªè©•ä¾¡
                drs_quality, quality_details = evaluator.comprehensive_quality_score(
                    prompt, baseline_text, drs_text)

                # NFEåŠ¹ç‡
                nfe_reduction = ((baseline_nfe - drs_nfe) / baseline_nfe) * 100

                # æ›–æ˜§åº¦åˆ†æ
                max_ambiguity = max(
                    ambiguity_scores) if ambiguity_scores else 0
                ambiguity_variance = np.var(
                    ambiguity_scores) if ambiguity_scores else 0
                meaningful_blocks = sum(
                    1 for score in ambiguity_scores if score > 0.15)

                # è©³ç´°ãªçµæœå‡ºåŠ›
                print(f"\nğŸ“Š è©³ç´°çµæœ:")
                print(f"  ğŸ¯ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³:")
                print(f"     NFE: {baseline_nfe}")
                print(f"     ãƒ†ã‚­ã‚¹ãƒˆ: {baseline_text[:200]}...")
                print(f"  âš¡ å¤§å¹…æ”¹å–„ç‰ˆDRS:")
                print(f"     NFE: {drs_nfe}")
                print(f"     ãƒ†ã‚­ã‚¹ãƒˆ: {drs_text[:200]}...")

                print(f"\nğŸ“ˆ å“è³ªåˆ†æ:")
                print(f"  ğŸ”„ NFEå‰Šæ¸›: {nfe_reduction:.1f}%")
                print(f"  ğŸ’ ç·åˆå“è³ªã‚¹ã‚³ã‚¢: {drs_quality:.3f}")
                print(
                    f"  ğŸ­ æ„å‘³çš„ä¸€è²«æ€§: {quality_details['semantic_consistency']:.3f}")
                print(
                    f"  ğŸ” åå¾©ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚¹ã‚³ã‚¢: {quality_details['repetition_score']:.3f}")
                print(f"  ğŸ“ é•·ã•æ¯”ç‡: {quality_details['length_ratio']:.3f}")
                print(f"  ğŸ¯ æœ€å¤§æ›–æ˜§åº¦: {max_ambiguity:.3f}")
                print(f"  ğŸ“Š æ›–æ˜§åº¦åˆ†æ•£: {ambiguity_variance:.3f}")
                print(
                    f"  ğŸ” æ„å‘³ã‚ã‚‹ãƒ–ãƒ­ãƒƒã‚¯: {meaningful_blocks}/{len(ambiguity_scores)}")

                # å³æ ¼ãªDRSä¾¡å€¤è©•ä¾¡ï¼ˆå“è³ªã‚’æœ€å„ªå…ˆï¼‰
                # æ„å‘³çš„ä¸€è²«æ€§ãŒé‡è¦
                semantic_ok = quality_details['semantic_consistency'] >= 0.8
                # åå¾©ãŒå°‘ãªã„
                repetition_ok = quality_details['repetition_score'] >= 0.7
                efficiency_ok = nfe_reduction >= 10                          # åŠ¹ç‡å‘ä¸Š

                if semantic_ok and repetition_ok and efficiency_ok:
                    drs_value = "âœ… TRUE - æ„å‘³ä¿æŒ&åŠ¹ç‡å‘ä¸Šé”æˆ"
                elif semantic_ok and repetition_ok:
                    drs_value = "âš ï¸ PARTIAL - å“è³ªä¿æŒã ãŒåŠ¹ç‡å‘ä¸Šé™å®šçš„"
                elif efficiency_ok:
                    drs_value = "âŒ FALSE - åŠ¹ç‡å‘ä¸Šã‚ã‚‹ãŒå“è³ªåŠ£åŒ–"
                else:
                    drs_value = "âŒ FALSE - å“è³ªãƒ»åŠ¹ç‡ã¨ã‚‚ã«å•é¡Œ"

                print(f"  ğŸ¯ DRSä¾¡å€¤è©•ä¾¡: {drs_value}")

                # ã‚ˆã‚Šè©³ç´°ãªåˆ†ææƒ…å ±
                if quality_details['semantic_consistency'] < 0.5:
                    print(f"  âš ï¸  è­¦å‘Š: é‡å¤§ãªæ„å‘³çš„ä¸ä¸€è‡´ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                if quality_details['repetition_score'] < 0.5:
                    print(f"  âš ï¸  è­¦å‘Š: éåº¦ãªåå¾©ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")

                # çµæœä¿å­˜
                results.append({
                    'prompt_id': i+1,
                    'condition': condition['name'],
                    'nfe_reduction': nfe_reduction,
                    'total_quality': drs_quality,
                    'semantic_consistency': quality_details['semantic_consistency'],
                    'repetition_score': quality_details['repetition_score'],
                    'length_ratio': quality_details['length_ratio'],
                    'max_ambiguity': max_ambiguity,
                    'ambiguity_variance': ambiguity_variance,
                    'meaningful_blocks': meaningful_blocks,
                    'drs_value': drs_value
                })

        # å…¨ä½“çš„ãªçµè«–
        print(f"\n{'='*80}")
        print("ğŸ¯ å¤§å¹…æ”¹å–„ç‰ˆæ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
        print(f"{'='*80}")

        successful_cases = sum(1 for r in results if 'TRUE' in r['drs_value'])
        partial_cases = sum(1 for r in results if 'PARTIAL' in r['drs_value'])
        total_cases = len(results)

        avg_nfe_reduction = np.mean([r['nfe_reduction'] for r in results])
        avg_total_quality = np.mean([r['total_quality'] for r in results])
        avg_semantic_consistency = np.mean(
            [r['semantic_consistency'] for r in results])

        print(f"ğŸ“Š çµ±è¨ˆ:")
        print(f"  âœ… å®Œå…¨æˆåŠŸ: {successful_cases}/{total_cases}")
        print(f"  âš ï¸ éƒ¨åˆ†æˆåŠŸ: {partial_cases}/{total_cases}")
        print(f"  ğŸ“‰ å¹³å‡NFEå‰Šæ¸›: {avg_nfe_reduction:.1f}%")
        print(f"  ğŸ’ å¹³å‡ç·åˆå“è³ª: {avg_total_quality:.3f}")
        print(f"  ğŸ­ å¹³å‡æ„å‘³çš„ä¸€è²«æ€§: {avg_semantic_consistency:.3f}")

        # ç ”ç©¶ä¾¡å€¤ã®æœ€çµ‚åˆ¤å®šï¼ˆã‚ˆã‚Šå³æ ¼ãªåŸºæº–ï¼‰
        semantic_success_rate = sum(
            1 for r in results if r['semantic_consistency'] >= 0.8) / total_cases

        if successful_cases >= total_cases * 0.5 and semantic_success_rate >= 0.8:
            final_conclusion = "âœ… DRSä»®èª¬ã¯æ¤œè¨¼ã•ã‚ŒãŸ - é«˜å“è³ªç¶­æŒ&åŠ¹ç‡å‘ä¸Šå®Ÿç¾"
        elif semantic_success_rate >= 0.6:
            final_conclusion = "âš ï¸ DRSä»®èª¬ã¯éƒ¨åˆ†çš„ã«æ¤œè¨¼ - æ„å‘³ä¿æŒã¯è‰¯å¥½ã ãŒåŠ¹ç‡è¦æ”¹å–„"
        else:
            final_conclusion = "âŒ DRSä»®èª¬ã¯æ¤œè¨¼ã•ã‚Œãš - æ„å‘³çš„ä¸€è²«æ€§ã«é‡å¤§ãªå•é¡Œ"

        print(f"\nğŸ¯ æœ€çµ‚çµè«–: {final_conclusion}")

        # æ”¹å–„ææ¡ˆ
        if semantic_success_rate < 0.8:
            print(f"\nğŸ’¡ æ”¹å–„ææ¡ˆ:")
            print(f"  1. å†ãƒã‚¹ã‚¯é–¾å€¤ã‚’ã•ã‚‰ã«ä¿å®ˆçš„ã«è¨­å®š (0.95+)")
            print(f"  2. å®Œæˆãƒ–ãƒ­ãƒƒã‚¯ã®å†ãƒã‚¹ã‚¯ã‚’å®Œå…¨ã«ç¦æ­¢")
            print(f"  3. ãƒ–ãƒ­ãƒƒã‚¯é–“ã®æ–‡è„ˆç¶™ç¶šæ€§ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’è¿½åŠ ")
            print(f"  4. æ„å‘³çš„æ¤œè¨¼ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã«çµ„ã¿è¾¼ã¿")

        return results

    except Exception as e:
        logger.error(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    results = test_enhanced_drs_validation()
    if results:
        print(f"\nâœ… å¤§å¹…æ”¹å–„ç‰ˆæ¤œè¨¼å®Œäº†")
    else:
        print(f"\nâŒ æ¤œè¨¼å¤±æ•—")
